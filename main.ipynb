{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5c07048a-f5ce-45b8-ac7c-635317e48800","cell_type":"markdown","source":"## Prepare Dataset","metadata":{}},{"id":"4db9400e-2549-4647-b23b-ec4e576bbc37","cell_type":"code","source":"! pip install -q accelerate peft lightning nltk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c11480f8-230a-46be-8849-ffe59703512e","cell_type":"code","source":"! pip install -U bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bc1cd899-8b35-482d-b1a8-de4d76936771","cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:31:04.275395Z","iopub.execute_input":"2024-12-20T03:31:04.275942Z","iopub.status.idle":"2024-12-20T03:31:04.535841Z","shell.execute_reply.started":"2024-12-20T03:31:04.275872Z","shell.execute_reply":"2024-12-20T03:31:04.534782Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f570262355d4f75a6c3b8c7bbe31d7e"}},"metadata":{}}],"execution_count":1},{"id":"26d4efa6-bbc6-4c86-85b5-e1e0c9450036","cell_type":"code","source":"# download dataset\n\nimport transformers\n\nfrom datasets import load_dataset\n\nDATA_REPO_ID = \"tanganke/stanford_cars\"\n\n\n\ntrain_dataset = load_dataset(DATA_REPO_ID, split=\"train\")\n\ntest_dataset  = load_dataset(DATA_REPO_ID, split=\"test\")\n# valid_dataset = load_dataset(DATA_REPO_ID, split=\"validation\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:31:12.207832Z","iopub.execute_input":"2024-12-20T03:31:12.208683Z","iopub.status.idle":"2024-12-20T03:31:20.454058Z","shell.execute_reply.started":"2024-12-20T03:31:12.208644Z","shell.execute_reply":"2024-12-20T03:31:20.453043Z"}},"outputs":[],"execution_count":2},{"id":"fda4c198-31d8-460c-a60b-ad9adc50ac5b","cell_type":"code","source":"# prepare collate function\n\nfrom transformers import AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")\n\ndef train_collate_fn(samples):\n\n    images = [sample[\"image\"] for sample in samples]\n\n    texts = [\"<image\" + \"<bos>\" + \"What is the model of a car in the image?\" for sample in samples]\n\n    labels = [sample[\"label\"]+\"<eos>\" for sample in samples]\n\n\n\n    # define a processor that handle max_length 128(not including the number of image tokens)\n\n    inputs = processor(text=texts, images=images, suffix=labels, return_tensors=\"pt\", \n\n                      padding=True, truncation=True, max_length=128)\n\n\n\n    input_ids = inputs[\"input_ids\"]\n\n    token_type_ids = inputs[\"token_type_ids\"]\n\n    attention_mask = inputs[\"attention_mask\"]\n\n    pixel_values = inputs[\"pixel_values\"]\n\n    labels = inputs[\"labels\"]\n\n\n\n    return input_ids, token_type_ids, attention_mask, pixel_values, labels\n\n\n\ndef test_collate_fn(samples):\n\n    images = [sample[\"image\"] for sample in samples]\n\n    texts = [\"<image\" + \"<bos>\" + \"What is the model of a car in the image?\" for sample in samples]\n\n    labels = [sample[\"label\"] + \"<eos>\" for sample in samples]\n\n\n\n    # define a processor that handle max_length 128(not including the number of image tokens)\n\n    inputs = processor(text=texts, images=images, return_tensors=\"pt\", \n\n                      padding=True, truncation=True, max_length=128)\n\n\n\n    input_ids = inputs[\"input_ids\"]\n\n    attention_mask = inputs[\"attention_mask\"]\n\n    pixel_values = inputs[\"pixel_values\"]\n\n\n\n    return input_ids, attention_mask, pixel_values, labels\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:38:13.323929Z","iopub.execute_input":"2024-12-20T03:38:13.324309Z","iopub.status.idle":"2024-12-20T03:38:17.306955Z","shell.execute_reply.started":"2024-12-20T03:38:13.324277Z","shell.execute_reply":"2024-12-20T03:38:17.306165Z"}},"outputs":[],"execution_count":17},{"id":"56718462-c8c3-4b41-ad36-b46b1ece960f","cell_type":"markdown","source":"## Prepare Quantization Settings","metadata":{}},{"id":"67c48c00-48e9-44a3-9746-ff7beaac1784","cell_type":"code","source":"# Using bitsandbytes library, setting the quantization\n\nfrom transformers import BitsAndBytesConfig\n\nimport torch\n\n\n\nbnb_config = BitsAndBytesConfig(\n\n    load_in_4bit=True,\n\n    bnb_4bit_compute_dtype=torch.bfloat16, # convert float32 to bf16 to speed up computation\n\n    bnb_4bit_quant_type=\"nf4\", # NF4 is 4-bit data type from QLoRA paper\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:31:28.175674Z","iopub.execute_input":"2024-12-20T03:31:28.176240Z","iopub.status.idle":"2024-12-20T03:31:28.186860Z","shell.execute_reply.started":"2024-12-20T03:31:28.176210Z","shell.execute_reply":"2024-12-20T03:31:28.185997Z"}},"outputs":[],"execution_count":4},{"id":"be6be565-111a-4369-86b2-1815ba745813","cell_type":"markdown","source":"## Prepare LoRA Settings","metadata":{}},{"id":"a24f35ef-9844-467e-a053-a91792936716","cell_type":"code","source":"from peft import LoraConfig\n\n\n\nlora_config = LoraConfig(\n\n    r=4, # set the low-rank as 4 \n\n    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], #modules that we are going to apply LoRA adapter\n\n    task_type=\"CAUSAL_LM\", # type of model. PaliGemma is causal language model\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:31:28.189183Z","iopub.execute_input":"2024-12-20T03:31:28.189849Z","iopub.status.idle":"2024-12-20T03:31:28.344838Z","shell.execute_reply.started":"2024-12-20T03:31:28.189808Z","shell.execute_reply":"2024-12-20T03:31:28.344117Z"}},"outputs":[],"execution_count":5},{"id":"045361e1-f555-4248-99a2-12735649a745","cell_type":"markdown","source":"## Prepare pytorch-lightning Trainer","metadata":{}},{"id":"96907c95-4e78-45d4-a66c-d3bead4fea84","cell_type":"code","source":"import lightning as L\n\nfrom transformers import AutoProcessor\n\nimport torch \n\nfrom nltk import edit_distance\n\nfrom torch.utils.data import DataLoader\n\n\n\n\n\nclass PaliGemma_Finetuned_Model(L.LightningModule):\n\n    def __init__(self, config, model, processor):\n        super().__init__()\n\n        self.model = model \n\n        self.processor = processor\n\n        self.config = config\n\n\n\n        self.batch_size = config.get(\"batch_size\")\n\n\n\n        self.train_losses = []\n\n        self.val_losses = []\n\n        self.val_scores = []\n\n\n\n    def training_step(self, batch, batch_idx):\n        print(batch)\n\n        input_ids, token_type_ids, attention_mask, pixel_values, labels = batch\n\n\n\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n\n                            pixel_values=pixel_values, labels=labels)\n\n\n\n        loss = outputs.loss\n\n\n\n        self.train_losses.append(loss.item())\n\n\n\n        self.log(\"train_loss\", loss)\n\n        return loss\n\n\n\n    def validation_step(self, batch, batch_idx):\n        print(batch)\n\n        input_ids, attention_mask, pixel_values, labels = batch\n\n\n\n        generated_ids = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values, max_new_tokens=80)\n        predictions = self.processor.batch_decode(generated_ids[:, input_ids.size(1)+1:], skip_special_tokes=True)\n    \n\n        scores = []\n\n        print(labels)\n        print(predictions)\n        \n\n        for pred, label in zip(predictions, labels):\n\n            score = edit_distance(pred, label) / max(len(pred), len(label))\n\n            self.val_scores.append(score)\n\n            scores.append(score)\n\n        self.log(\"val_edit_distance\", np.mean(scores), on_epoch=True)\n\n\n\n        return scores\n\n\n\n    def configure_optimizers(self):\n\n        optimizer = torch.optim.AdamW(self.parameters(), lr=config.get(\"lr\", 3e-4))\n\n        return optimizer\n\n\n\n    def train_dataloader(self):\n\n        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=train_collate_fn, num_workers=3)\n\n    def val_dataloader(self):\n\n        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=test_collate_fn, num_workers=3)\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:40:15.569235Z","iopub.execute_input":"2024-12-20T03:40:15.570060Z","iopub.status.idle":"2024-12-20T03:40:15.581476Z","shell.execute_reply.started":"2024-12-20T03:40:15.570018Z","shell.execute_reply":"2024-12-20T03:40:15.580454Z"}},"outputs":[],"execution_count":27},{"id":"5a733a06-ed00-420a-8c48-8e60a4c4976d","cell_type":"markdown","source":"## Define the model ","metadata":{}},{"id":"9e131d3d-04bd-4f1e-b8ca-02a1481a8e6d","cell_type":"code","source":"from transformers import PaliGemmaForConditionalGeneration\n\nfrom peft import get_peft_model\n\n\n\nmodel = PaliGemmaForConditionalGeneration.from_pretrained(\"google/paligemma-3b-pt-224\", quantization_config=bnb_config)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:40:19.688746Z","iopub.execute_input":"2024-12-20T03:40:19.689604Z","iopub.status.idle":"2024-12-20T03:40:42.979997Z","shell.execute_reply.started":"2024-12-20T03:40:19.689567Z","shell.execute_reply":"2024-12-20T03:40:42.979008Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8228ffa7f25340c6b89b8e1a3fa5b85c"}},"metadata":{}}],"execution_count":28},{"id":"7654cd6e-b62d-4273-b03d-60c61c0d7e40","cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:38:38.536969Z","iopub.execute_input":"2024-12-20T03:38:38.537834Z","iopub.status.idle":"2024-12-20T03:38:38.550140Z","shell.execute_reply.started":"2024-12-20T03:38:38.537799Z","shell.execute_reply":"2024-12-20T03:38:38.549230Z"}},"outputs":[{"name":"stdout","text":"trainable params: 5,649,408 || all params: 2,929,115,888 || trainable%: 0.1929\n","output_type":"stream"}],"execution_count":20},{"id":"bb1f970e-503c-4571-bfb4-5cde62567fc9","cell_type":"markdown","source":"## Setup Training Configurations","metadata":{}},{"id":"d7debc62-d578-410d-b205-e1fb6b657b7b","cell_type":"code","source":"config = config = {\n            \"max_epochs\": 100,\n\n          \"check_val_every_n_epoch\": 1,\n\n          \"gradient_clip_val\": 1.0,\n\n          \"accumulate_grad_batches\": 8,\n\n          \"lr\": 3e-4,\n\n          \"batch_size\": 2,\n\n          \"seed\":1234,\n\n          \"num_nodes\": 1,\n\n          \"warmup_steps\": 50,\n\n          \"result_path\": \"./result\",\n\n          \"verbose\": True,\n\n}\n\n\n\nmodel_module = PaliGemma_Finetuned_Model(config, model, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:40:46.910889Z","iopub.execute_input":"2024-12-20T03:40:46.911269Z","iopub.status.idle":"2024-12-20T03:40:46.916472Z","shell.execute_reply.started":"2024-12-20T03:40:46.911238Z","shell.execute_reply":"2024-12-20T03:40:46.915424Z"}},"outputs":[],"execution_count":30},{"id":"941ae29e-765d-4500-b384-39c8e332572a","cell_type":"markdown","source":"## Define Callbacks","metadata":{}},{"id":"59037b17-be93-45c6-8592-1d37581bb2e4","cell_type":"code","source":"from lightning.pytorch.callbacks import Callback\n\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\n\nfrom huggingface_hub import HfApi\n\n\n\napi = HfApi()\n\n\n\nFINETUNED_MODEL_ID=\"ball1433/PaliGemma-StanfordCars-finetuned\"\n\n\n\nclass Print_TrainValidation_ResultCallback(Callback):\n\n    def on_train_epoch_end(self, trainer, pl_module):\n\n        # print the average of training loss \n\n        print(f'Average Training Loss: {np.mean(pl_module.train_losses)}')\n\n\n\n        # print the average of edit distance score\n\n        print(f'Average Validation Score: {np.mean(pl_module.val_scores)}')\n\n\n\n        # reset the list\n\n        pl_module.train_losses = []\n\n        pl_module.val_scores = []\n\n\n\n\n\nclass PushToHubCallback(Callback):\n\n    def on_train_epoch_end(self, trainer, pl_module):\n\n        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n\n        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n\n                                    commit_message=f\"Training in progress, epoch {trainer.current_epoch}\")\n\n\n\n    def on_train_end(self, trainer, pl_module):\n\n        print(f\"Pushing model to the hub after training\")\n\n        pl_module.processor.push_to_hub(FINETUNED_MODEL_ID,\n\n                                    commit_message=f\"Training done\")\n\n        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n\n                                    commit_message=f\"Training done\")\n\n\n\nearly_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=20, verbose=False, mode=\"min\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:40:50.504033Z","iopub.execute_input":"2024-12-20T03:40:50.504378Z","iopub.status.idle":"2024-12-20T03:40:50.512124Z","shell.execute_reply.started":"2024-12-20T03:40:50.504352Z","shell.execute_reply":"2024-12-20T03:40:50.511169Z"}},"outputs":[],"execution_count":31},{"id":"95a43f57-6379-4bf5-95b8-745eb9ec1737","cell_type":"markdown","source":"## Training","metadata":{}},{"id":"c5b43acc-eecd-483c-bb86-607deab32d7f","cell_type":"code","source":"# define trainer \n\ntrainer = L.Trainer(\n\n        devices=-1, \n\n        accelerator=\"auto\",\n\n        max_epochs=config.get(\"max_epochs\"),\n\n        accumulate_grad_batches=config.get(\"accumulate_grad_batches\"),\n\n        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n\n        gradient_clip_val=config.get(\"gradient_clip_val\"),\n\n        precision=\"16-mixed\",\n\n        limit_val_batches=1.0,\n\n        num_sanity_val_steps=2,\n\n        callbacks=[PushToHubCallback(), Print_TrainValidation_ResultCallback(), early_stop_callback],\n\n)\n\n\n\ntrainer.fit(model_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T03:40:53.213254Z","iopub.execute_input":"2024-12-20T03:40:53.214136Z","iopub.status.idle":"2024-12-20T03:40:56.387858Z","shell.execute_reply.started":"2024-12-20T03:40:53.214086Z","shell.execute_reply":"2024-12-20T03:40:56.386130Z"}},"outputs":[{"name":"stderr","text":"INFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\nINFO: \n  | Name  | Type                 | Params | Mode \n-------------------------------------------------------\n0 | model | PeftModelForCausalLM | 1.7 B  | train\n-------------------------------------------------------\n5.6 M     Trainable params\n1.7 B     Non-trainable params\n1.7 B     Total params\n6,925.987 Total estimated model params size (MB)\n2072      Modules in train mode\n593       Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29ba16cf3b34f63b399444979a35ce6"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 29\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# define trainer \u001b[39;00m\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m         devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_module\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_502/2405541102.py\", line 47, in test_collate_fn\n    labels = [sample[\"label\"] + \"<eos>\" for sample in samples]\n  File \"/tmp/ipykernel_502/2405541102.py\", line 47, in <listcomp>\n    labels = [sample[\"label\"] + \"<eos>\" for sample in samples]\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n"],"ename":"TypeError","evalue":"Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_502/2405541102.py\", line 47, in test_collate_fn\n    labels = [sample[\"label\"] + \"<eos>\" for sample in samples]\n  File \"/tmp/ipykernel_502/2405541102.py\", line 47, in <listcomp>\n    labels = [sample[\"label\"] + \"<eos>\" for sample in samples]\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n","output_type":"error"}],"execution_count":32},{"id":"ac92c16d-1ace-4e15-94f4-67c70a50d3a5","cell_type":"markdown","source":"## Inference","metadata":{}}]}
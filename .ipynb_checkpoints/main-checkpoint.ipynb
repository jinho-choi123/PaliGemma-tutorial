{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c07048a-f5ce-45b8-ac7c-635317e48800",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1cd899-8b35-482d-b1a8-de4d76936771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ff32e3e5ad4d248cd5a82994f79f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4efa6-bbc6-4c86-85b5-e1e0c9450036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "DATA_REPO_ID = \"tanganke/stanford_cars\"\n",
    "\n",
    "train_dataset = load_dataset(DATA_REPO_ID, split=\"train\")\n",
    "valid_dataset = load_dataset(DATA_REPO_ID, split=\"validation\")\n",
    "test_dataset  = load_dataset(DATA_REPO_ID, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4c198-31d8-460c-a60b-ad9adc50ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare collate function\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
    "\n",
    "def train_collate_fn(samples):\n",
    "    images = [sample[\"image\"] for sample in samples]\n",
    "    texts = [\"What is the model of a car in the image?\" for sample in samples]\n",
    "    labels = [sample[\"label\"] for sample in samples]\n",
    "\n",
    "    # define a processor that handle max_length 128(not including the number of image tokens)\n",
    "    inputs = processor(text=texts, images=images, suffix=labels, return_tensors=\"pt\", \n",
    "                      padding=True, truncation=True, max_length=128)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    pixel_values = inputs[\"pixel_values\"]\n",
    "    labels = inputs[\"labels\"]\n",
    "\n",
    "    return input_ids, token_type_ids, attention_mask, pixel_values, labels\n",
    "\n",
    "def test_collate_fn(samples):\n",
    "    images = [sample[\"image\"] for sample in samples]\n",
    "    texts = [\"What is the model of a car in the image?\" for sample in samples]\n",
    "    labels = [sample[\"label\"] for sample in samples]\n",
    "\n",
    "    # define a processor that handle max_length 128(not including the number of image tokens)\n",
    "    inputs = processor(text=texts, images=images, return_tensors=\"pt\", \n",
    "                      padding=True, truncation=True, max_length=128)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    pixel_values = inputs[\"pixel_values\"]\n",
    "\n",
    "    return input_ids, attention_mask, pixel_values, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56718462-c8c3-4b41-ad36-b46b1ece960f",
   "metadata": {},
   "source": [
    "## Prepare Quantization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c48c00-48e9-44a3-9746-ff7beaac1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using bitsandbytes library, setting the quantization\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # convert float32 to bf16 to speed up computation\n",
    "    bnb_4bit_quant_type=\"nf4\", # NF4 is 4-bit data type from QLoRA paper\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6be565-111a-4369-86b2-1815ba745813",
   "metadata": {},
   "source": [
    "## Prepare LoRA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f35ef-9844-467e-a053-a91792936716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4, # set the low-rank as 4 \n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], #modules that we are going to apply LoRA adapter\n",
    "    task_type=\"CAUSAL_LM\", # type of model. PaliGemma is causal language model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045361e1-f555-4248-99a2-12735649a745",
   "metadata": {},
   "source": [
    "## Prepare pytorch-lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96907c95-4e78-45d4-a66c-d3bead4fea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from transformers import AutoProcessor\n",
    "import torch \n",
    "from nltk import edit_distance\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class PaliGemma_Finetuned_Model(L.LightningModule):\n",
    "    def __init__(self, config, model, processor):\n",
    "        self.model = model \n",
    "        self.processor = processor\n",
    "        self.config = config\n",
    "\n",
    "        self.batch_size = config.get(\"batch_size\")\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_scores = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, token_type_ids, attention_mask, pixel_values, labels = batch\n",
    "\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                            pixel_values=pixel_values, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        self.train_losses.append(loss.item())\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, pixel_values, labels = batch\n",
    "\n",
    "        generated_ids = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values, max_new_tokens=80)\n",
    "        scores = []\n",
    "        \n",
    "        for pred, label in zip(predictions, labels):\n",
    "            score = edit_distance(pred, label) / max(len(pred), len(label))\n",
    "            self.val_scores.append(score)\n",
    "            scores.append(score)\n",
    "        self.log(\"val_edit_distance\", np.mean(scores), on_epoch=True)\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=config.get(\"lr\", 3e-4))\n",
    "        return optimizer=optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=train_collate_fn, num_workers=3)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=test_collate_fn, num_workers=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a733a06-ed00-420a-8c48-8e60a4c4976d",
   "metadata": {},
   "source": [
    "## Define the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e131d3d-04bd-4f1e-b8ca-02a1481a8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PaliGemmaForConditionalGeneration\n",
    "from peft import get_peft_model\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\"google/paligemma-3b-pt-224\", quantization_config=bnb_config)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654cd6e-b62d-4273-b03d-60c61c0d7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f970e-503c-4571-bfb4-5cde62567fc9",
   "metadata": {},
   "source": [
    "## Setup Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7debc62-d578-410d-b205-e1fb6b657b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config = {\"max_epochs\": EPOCHS,\n",
    "          \"check_val_every_n_epoch\": 1,\n",
    "          \"gradient_clip_val\": 1.0,\n",
    "          \"accumulate_grad_batches\": 8,\n",
    "          \"lr\": 3e-4,\n",
    "          \"batch_size\": 2,\n",
    "          \"seed\":1234,\n",
    "          \"num_nodes\": 1,\n",
    "          \"warmup_steps\": 50,\n",
    "          \"result_path\": \"./result\",\n",
    "          \"verbose\": True,\n",
    "}\n",
    "\n",
    "model_module = PaliGemma_Finetuned_Model(config, processor, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ae29e-765d-4500-b384-39c8e332572a",
   "metadata": {},
   "source": [
    "## Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59037b17-be93-45c6-8592-1d37581bb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "FINETUNED_MODEL_ID=\"ball1433/PaliGemma-StanfordCars-finetuned\"\n",
    "\n",
    "class Print_TrainValidation_ResultCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # print the average of training loss \n",
    "        print(f'Average Training Loss: {np.mean(pl_module.train_losses)}')\n",
    "\n",
    "        # print the average of edit distance score\n",
    "        print(f'Average Validation Score: {np.mean(pl_module.val_scores)}')\n",
    "\n",
    "        # reset the list\n",
    "        pl_module.train_losses = []\n",
    "        pl_module.val_scores = []\n",
    "\n",
    "\n",
    "class PushToHubCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n",
    "        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training in progress, epoch {trainer.current_epoch}\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub after training\")\n",
    "        pl_module.processor.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training done\")\n",
    "        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training done\")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=20, verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a43f57-6379-4bf5-95b8-745eb9ec1737",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b43acc-eecd-483c-bb86-607deab32d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trainer \n",
    "trainer = L.Trainer(\n",
    "        devices=-1, \n",
    "        accelerator=\"auto\",\n",
    "        max_epochs=config.get(\"max_epochs\"),\n",
    "        accumulate_grad_batches=config.get(\"accumulate_grad_batches\"),\n",
    "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "        precision=\"16-mixed\",\n",
    "        limit_val_batches=1.0,\n",
    "        num_sanity_val_steps=2,\n",
    "        callbacks=[PushToHubCallback(), Print_TrainValidation_ResultCallback(), early_stop_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92c16d-1ace-4e15-94f4-67c70a50d3a5",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
